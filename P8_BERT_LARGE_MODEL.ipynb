{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonnefco/P8/blob/main/P8_BERT_LARGE_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfREIvCPHHSe"
      },
      "source": [
        "# Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "SWSzYlbMK8fm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import ast\n",
        "from scipy import stats\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-vdZ2FeX6R7",
        "outputId": "01026a4d-4155-4369-efcd-852493599c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.96)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->transformers[sentencepiece]) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import TFAutoModel, AutoConfig\n",
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "HiZJC33N9AFr"
      },
      "outputs": [],
      "source": [
        "tensorflow.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLLVVqHBkw5g"
      },
      "source": [
        "# Fonctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "GsoLMjxrkzAz"
      },
      "outputs": [],
      "source": [
        "def plot_curves(history):\n",
        "\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kO9gxdz6Rkt"
      },
      "source": [
        "# Importation du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "LaqotQtj6Y8-"
      },
      "outputs": [],
      "source": [
        "df_effective_args = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/P8/dataset/train.csv',encoding=\"utf-8\",header=(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEgC5fra6g5u"
      },
      "source": [
        "## Lier chaque discourse_id avec le texte integrale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Q_Yl8qXfGKLp"
      },
      "outputs": [],
      "source": [
        "def create_dict_key_id___value_essay_text(path_folder):\n",
        "\n",
        "  list_texts_essay = glob.glob(path_folder + '/*')\n",
        "  dictionnary = {}\n",
        "  for text in list_texts_essay : \n",
        "      essay_text = open(text, 'r').read()\n",
        "      id_essay = text.split('/')[-1].split('.')[0]\n",
        "      dictionnary[id_essay] = essay_text\n",
        "\n",
        "  return dictionnary\n",
        "\n",
        "def df_link_essay_id_and_text_essay(df, path_folder) :\n",
        "  dictionnary_key_id___value_essay_text = create_dict_key_id___value_essay_text(path_folder)\n",
        "  df['essay_text'] = df['essay_id'].map(dictionnary_key_id___value_essay_text)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ZBzfhULNHs7e"
      },
      "outputs": [],
      "source": [
        "path_train_folder = '/content/drive/MyDrive/Colab_Notebooks/P8/dataset/train'\n",
        "df_effective_args = df_link_essay_id_and_text_essay(df_effective_args, path_train_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nettoyage "
      ],
      "metadata": {
        "id": "IXirOw62Re1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Suppression incohérence du dataset"
      ],
      "metadata": {
        "id": "zcYKMXMeStXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#doublons possèdent deux \"discourse_effectiveness\" différents\n",
        "df_duplicates = df_effective_args[df_effective_args.duplicated(subset=['discourse_text'], keep=False)]\n",
        "df_duplicates_different_discourse_effectiveness = df_duplicates[~df_duplicates.duplicated(subset=['discourse_text', 'discourse_effectiveness'], keep=False)]\n",
        "list_index_to_drop = df_duplicates_different_discourse_effectiveness.index.values.tolist()\n",
        "\n",
        "#doublons possèdent deux \"discourse_type\" différents\n",
        "df_duplicates_different_discourse_type = df_duplicates[~df_duplicates.duplicated(subset=['discourse_text', 'discourse_type'], keep=False)]\n",
        "list_index_to_drop += df_duplicates_different_discourse_type.index.values.tolist()\n",
        "df_without_incoherence = df_effective_args.drop(list_index_to_drop, axis=0)\n",
        "\n",
        "#Conservation d'un doublon sur deux\n",
        "df_effective_args_without_duplicates = df_without_incoherence.drop_duplicates(subset=['discourse_text'], keep='first')"
      ],
      "metadata": {
        "id": "nf_yoYtRQ7vL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O8ayoZm-26e"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUtBixum-1OY"
      },
      "outputs": [],
      "source": [
        "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
        "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
        "\n",
        "\n",
        "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
        "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
        "\n",
        "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
        "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
        "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
        "\n",
        "def resolve_encodings_and_normalize(text: str) -> str:\n",
        "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
        "    text = (\n",
        "        text.encode(\"raw_unicode_escape\")\n",
        "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
        "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
        "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
        "    )\n",
        "    text = unidecode(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzkjtxYhYpGS"
      },
      "source": [
        "# Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR25rZOtYrCf"
      },
      "outputs": [],
      "source": [
        "Cfg = {\n",
        "    # Model Configs\n",
        "    \"model_name\": \"microsoft/deberta-v3-large\",\n",
        "    \"max_len\": 512,\n",
        "    \n",
        "    # Train Configs\n",
        "    \"fold_num\": 5,\n",
        "    \"lr\": 5e-6,\n",
        "    \"batch_size\": 8,\n",
        "    \"valid_batch_size\": 32,\n",
        "    \"epochs\": 1,\n",
        "    \n",
        "    # Path\n",
        "    \"path_input_csv\": '/content/drive/MyDrive/Colab_Notebooks/P8/dataset/train_light.csv',\n",
        "    \"path_output_save_h5_model\" : '/content/drive/MyDrive/Colab_Notebooks/P8/models'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PND4zOZ6ZjEK"
      },
      "outputs": [],
      "source": [
        "Dictionnary_to_encode_effectivness = {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxMaC1lck9Wh"
      },
      "source": [
        "# Init Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLfjTDl_kUtW",
        "outputId": "cd54fc6b-99dd-4bea-ddd6-b1f84e365962"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer_BERT = transformers.AutoTokenizer.from_pretrained(Cfg['model_name'], use_fast=True, max_length = Cfg['max_len'])\n",
        "#tokenizer_BERT(pad_token = '[PAD]', truncation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o2KKdpAkUoE",
        "outputId": "bedf2d68-fda5-4191-dce2-948bbf7c1f9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DebertaV2Config {\n",
              "  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 1024,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 4096,\n",
              "  \"layer_norm_eps\": 1e-07,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"max_relative_positions\": -1,\n",
              "  \"model_type\": \"deberta-v2\",\n",
              "  \"norm_rel_ebd\": \"layer_norm\",\n",
              "  \"num_attention_heads\": 16,\n",
              "  \"num_hidden_layers\": 24,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_dropout\": 0,\n",
              "  \"pooler_hidden_act\": \"gelu\",\n",
              "  \"pooler_hidden_size\": 1024,\n",
              "  \"pos_att_type\": [\n",
              "    \"p2c\",\n",
              "    \"c2p\"\n",
              "  ],\n",
              "  \"position_biased_input\": false,\n",
              "  \"position_buckets\": 256,\n",
              "  \"relative_attention\": true,\n",
              "  \"share_att_key\": true,\n",
              "  \"transformers_version\": \"4.21.1\",\n",
              "  \"type_vocab_size\": 0,\n",
              "  \"vocab_size\": 128100\n",
              "}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AutoConfig.from_pretrained(Cfg['model_name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR9WeYlHrkOx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFPQKJUJZxoj"
      },
      "outputs": [],
      "source": [
        "def _prepare_training_data_helper(cfg, tokenizer, df, is_train):\n",
        "    training_samples = []\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        idx = row[\"essay_id\"]\n",
        "        discourse_text = row[\"discourse_text\"]\n",
        "        discourse_type = row[\"discourse_type\"]\n",
        "\n",
        "        if is_train:\n",
        "            filename = os.path.join(cfg.input, \"train_light\", idx + \".txt\")\n",
        "        else:\n",
        "            filename = os.path.join(cfg.input, \"test\", idx + \".txt\")\n",
        "\n",
        "        with open(filename, \"r\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        encoded_text = tokenizer.encode_plus(\n",
        "            discourse_type + \" \" + discourse_text,\n",
        "            text,\n",
        "            add_special_tokens=False,\n",
        "        )\n",
        "        input_ids = encoded_text[\"input_ids\"]\n",
        "\n",
        "        sample = {\n",
        "            \"discourse_id\": row[\"discourse_id\"],\n",
        "            \"input_ids\": input_ids,\n",
        "            # \"discourse_text\": discourse_text,\n",
        "            # \"essay_text\": text,\n",
        "            # \"mask\": encoded_text[\"attention_mask\"],\n",
        "        }\n",
        "\n",
        "        if \"token_type_ids\" in encoded_text:\n",
        "            sample[\"token_type_ids\"] = encoded_text[\"token_type_ids\"]\n",
        "\n",
        "        label = row[\"discourse_effectiveness\"]\n",
        "\n",
        "        sample[\"label\"] = LABEL_MAPPING[label]\n",
        "\n",
        "        training_samples.append(sample)\n",
        "    return training_samples\n",
        "\n",
        "\n",
        "def prepare_training_data(df, tokenizer, cfg, num_jobs, is_train):\n",
        "    training_samples = []\n",
        "\n",
        "    df_splits = np.array_split(df, num_jobs)\n",
        "\n",
        "    results = Parallel(n_jobs=num_jobs, backend=\"multiprocessing\")(\n",
        "        delayed(_prepare_training_data_helper)(cfg, tokenizer, df, is_train) for df in df_splits\n",
        "    )\n",
        "    for result in results:\n",
        "        training_samples.extend(result)\n",
        "\n",
        "    return training_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va_SVEYjB0aW"
      },
      "source": [
        "# Fonctions utiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWFT7iW3iTfQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGhjeFIqB3kv"
      },
      "source": [
        "# Nettoyage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VuZ595O-MNx"
      },
      "source": [
        "## Chargement fichier source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SxU2y1tJRj-P",
        "outputId": "4f54d24f-7c0c-442c-be1c-15611860cff5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-383dd7e8-58c1-4b32-9513-d7a50adc40bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If life was on Mars, we would know by now. The...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>People thought that the face was formed by ali...</td>\n",
              "      <td>Counterclaim</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36672</th>\n",
              "      <td>For many people they don't like only asking on...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36673</th>\n",
              "      <td>also people have different views and opinions ...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36674</th>\n",
              "      <td>Advice is something that can impact a persons ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36675</th>\n",
              "      <td>someone can use everything that many people sa...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Ineffective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36676</th>\n",
              "      <td>In conclusion asking for an opinion can be ben...</td>\n",
              "      <td>Concluding Statement</td>\n",
              "      <td>Ineffective</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36677 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-383dd7e8-58c1-4b32-9513-d7a50adc40bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-383dd7e8-58c1-4b32-9513-d7a50adc40bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-383dd7e8-58c1-4b32-9513-d7a50adc40bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          discourse_text  \\\n",
              "0      Hi, i'm Isaac, i'm going to be writing about h...   \n",
              "1      On my perspective, I think that the face is a ...   \n",
              "2      I think that the face is a natural landform be...   \n",
              "3      If life was on Mars, we would know by now. The...   \n",
              "4      People thought that the face was formed by ali...   \n",
              "...                                                  ...   \n",
              "36672  For many people they don't like only asking on...   \n",
              "36673  also people have different views and opinions ...   \n",
              "36674  Advice is something that can impact a persons ...   \n",
              "36675  someone can use everything that many people sa...   \n",
              "36676  In conclusion asking for an opinion can be ben...   \n",
              "\n",
              "             discourse_type discourse_effectiveness  \n",
              "0                      Lead                Adequate  \n",
              "1                  Position                Adequate  \n",
              "2                     Claim                Adequate  \n",
              "3                  Evidence                Adequate  \n",
              "4              Counterclaim                Adequate  \n",
              "...                     ...                     ...  \n",
              "36672                 Claim                Adequate  \n",
              "36673                 Claim                Adequate  \n",
              "36674              Position                Adequate  \n",
              "36675              Evidence             Ineffective  \n",
              "36676  Concluding Statement             Ineffective  \n",
              "\n",
              "[36677 rows x 3 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_effective_args = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/P8/dataset/train_light.csv',encoding=\"utf-8\",header=(0))\n",
        "df_effective_args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lxdwflf-QR7"
      },
      "source": [
        "## Encodage des labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMv2kUA2nFC2"
      },
      "outputs": [],
      "source": [
        "df_effective_args[\"discourse_effectiveness_number\"] = df_effective_args[\"discourse_effectiveness\"].replace({\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9cjSazV2Wgk"
      },
      "source": [
        "credits : https://www.kaggle.com/code/iamleonie/feedback-prize-eda-starter-for-beginners\n",
        "\n",
        "Get the sep_token from the tokenizer and create the input sequences from discourse_type and discourse_text.\n",
        "\n",
        "sep_token - A special token separating two different sentences in the same input (see https://huggingface.co/docs/transformers/main_classes/tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8kj_yhI-cxs"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezVhGxtq0f-C",
        "outputId": "94a809d4-ee02-4e92-f90e-ffa0dede0df8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "xMTL-JjH1C62",
        "outputId": "8fcff920-8309-428d-c6de-db7160543d64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ec797f87-d6f9-41a6-88d1-d8d97b1284e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>discourse_effectiveness_number</th>\n",
              "      <th>discourse_type_SEP_discourse_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>1</td>\n",
              "      <td>Lead[SEP]Hi, i'm Isaac, i'm going to be writin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>1</td>\n",
              "      <td>Position[SEP]On my perspective, I think that t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>1</td>\n",
              "      <td>Claim[SEP]I think that the face is a natural l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec797f87-d6f9-41a6-88d1-d8d97b1284e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec797f87-d6f9-41a6-88d1-d8d97b1284e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec797f87-d6f9-41a6-88d1-d8d97b1284e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                      discourse_text discourse_type  \\\n",
              "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
              "1  On my perspective, I think that the face is a ...       Position   \n",
              "2  I think that the face is a natural landform be...          Claim   \n",
              "\n",
              "  discourse_effectiveness  discourse_effectiveness_number  \\\n",
              "0                Adequate                               1   \n",
              "1                Adequate                               1   \n",
              "2                Adequate                               1   \n",
              "\n",
              "                   discourse_type_SEP_discourse_text  \n",
              "0  Lead[SEP]Hi, i'm Isaac, i'm going to be writin...  \n",
              "1  Position[SEP]On my perspective, I think that t...  \n",
              "2  Claim[SEP]I think that the face is a natural l...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sep = tokenizer_BERT.sep_token\n",
        "df_effective_args['discourse_type_SEP_discourse_text'] = df_effective_args.discourse_type + sep + df_effective_args.discourse_text\n",
        "df_effective_args.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pW2NmUL-kLc"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT901AymF9MZ"
      },
      "outputs": [],
      "source": [
        "df_effective_args['discourse_tokenized'] = df_effective_args['discourse_type_SEP_discourse_text'].apply(tokenizer_BERT.tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "jzK8LFj2KzeI",
        "outputId": "784c9edf-7069-45fd-ac13-4a21e098dd06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d9f55903-7cff-484a-bc6b-e067f820b44e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>discourse_effectiveness_number</th>\n",
              "      <th>discourse_type_SEP_discourse_text</th>\n",
              "      <th>discourse_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>1</td>\n",
              "      <td>Lead[SEP]Hi, i'm Isaac, i'm going to be writin...</td>\n",
              "      <td>[▁lead, [SEP], ▁hi, ,, ▁i, ', m, ▁is, a, ac, ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>1</td>\n",
              "      <td>Position[SEP]On my perspective, I think that t...</td>\n",
              "      <td>[▁position, [SEP], ▁on, ▁my, ▁perspective, ,, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>1</td>\n",
              "      <td>Claim[SEP]I think that the face is a natural l...</td>\n",
              "      <td>[▁claim, [SEP], ▁i, ▁think, ▁that, ▁the, ▁face...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9f55903-7cff-484a-bc6b-e067f820b44e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9f55903-7cff-484a-bc6b-e067f820b44e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9f55903-7cff-484a-bc6b-e067f820b44e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                      discourse_text discourse_type  \\\n",
              "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
              "1  On my perspective, I think that the face is a ...       Position   \n",
              "2  I think that the face is a natural landform be...          Claim   \n",
              "\n",
              "  discourse_effectiveness  discourse_effectiveness_number  \\\n",
              "0                Adequate                               1   \n",
              "1                Adequate                               1   \n",
              "2                Adequate                               1   \n",
              "\n",
              "                   discourse_type_SEP_discourse_text  \\\n",
              "0  Lead[SEP]Hi, i'm Isaac, i'm going to be writin...   \n",
              "1  Position[SEP]On my perspective, I think that t...   \n",
              "2  Claim[SEP]I think that the face is a natural l...   \n",
              "\n",
              "                                 discourse_tokenized  \n",
              "0  [▁lead, [SEP], ▁hi, ,, ▁i, ', m, ▁is, a, ac, ,...  \n",
              "1  [▁position, [SEP], ▁on, ▁my, ▁perspective, ,, ...  \n",
              "2  [▁claim, [SEP], ▁i, ▁think, ▁that, ▁the, ▁face...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_effective_args.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meL3YSia-nB3"
      },
      "source": [
        "## Longueur chaine de caractere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KvPmCrwK_1j"
      },
      "outputs": [],
      "source": [
        "def counter_len_in_text(string):\n",
        "  return len(string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EvN8WfuLB7U"
      },
      "outputs": [],
      "source": [
        "df_effective_args['Longueur_texte'] = df_effective_args['discourse_tokenized'].apply(counter_len_in_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "DDtkJrglLLM2",
        "outputId": "2be562a0-fbea-4370-bb9a-c1b5ec58d797"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-06a3b2f1-2ebf-4b25-9e86-94bccea3f341\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>discourse_effectiveness_number</th>\n",
              "      <th>discourse_type_SEP_discourse_text</th>\n",
              "      <th>discourse_tokenized</th>\n",
              "      <th>Longueur_texte</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>1</td>\n",
              "      <td>Lead[SEP]Hi, i'm Isaac, i'm going to be writin...</td>\n",
              "      <td>[▁lead, [SEP], ▁hi, ,, ▁i, ', m, ▁is, a, ac, ,...</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>1</td>\n",
              "      <td>Position[SEP]On my perspective, I think that t...</td>\n",
              "      <td>[▁position, [SEP], ▁on, ▁my, ▁perspective, ,, ...</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>1</td>\n",
              "      <td>Claim[SEP]I think that the face is a natural l...</td>\n",
              "      <td>[▁claim, [SEP], ▁i, ▁think, ▁that, ▁the, ▁face...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06a3b2f1-2ebf-4b25-9e86-94bccea3f341')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06a3b2f1-2ebf-4b25-9e86-94bccea3f341 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06a3b2f1-2ebf-4b25-9e86-94bccea3f341');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                      discourse_text discourse_type  \\\n",
              "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
              "1  On my perspective, I think that the face is a ...       Position   \n",
              "2  I think that the face is a natural landform be...          Claim   \n",
              "\n",
              "  discourse_effectiveness  discourse_effectiveness_number  \\\n",
              "0                Adequate                               1   \n",
              "1                Adequate                               1   \n",
              "2                Adequate                               1   \n",
              "\n",
              "                   discourse_type_SEP_discourse_text  \\\n",
              "0  Lead[SEP]Hi, i'm Isaac, i'm going to be writin...   \n",
              "1  Position[SEP]On my perspective, I think that t...   \n",
              "2  Claim[SEP]I think that the face is a natural l...   \n",
              "\n",
              "                                 discourse_tokenized  Longueur_texte  \n",
              "0  [▁lead, [SEP], ▁hi, ,, ▁i, ', m, ▁is, a, ac, ,...              88  \n",
              "1  [▁position, [SEP], ▁on, ▁my, ▁perspective, ,, ...              50  \n",
              "2  [▁claim, [SEP], ▁i, ▁think, ▁that, ▁the, ▁face...              25  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_effective_args.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "bGjU2jGfLUat",
        "outputId": "5a557727-08ec-45f3-d757-f57cc061a3dc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur du 99eme percentile = 257.0\n"
          ]
        }
      ],
      "source": [
        "plt.figure()\n",
        "df_effective_args['Longueur_texte'].hist(bins=150)\n",
        "plt.axvline(df_effective_args['Longueur_texte'].mean(), color='g', linestyle='dashed', linewidth=1)\n",
        "plt.axvline(df_effective_args['Longueur_texte'].median(), color='r', linestyle='dashed', linewidth=1)\n",
        "plt.axvline(df_effective_args['Longueur_texte'].quantile(.99), color='b', linestyle='dashed', linewidth=1)\n",
        "plt.show()\n",
        "\n",
        "print('valeur du 99eme percentile =', df_effective_args['Longueur_texte'].quantile(.99))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL2toY3X8pEA"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 270"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x470jk7t-yr-"
      },
      "source": [
        "# Encodage BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wafMjT0Y3uxe"
      },
      "outputs": [],
      "source": [
        "# sample_sequence = df_effective_args['discourse_type_SEP_discourse_text'].iloc[500]\n",
        "# print(sample_sequence)\n",
        "\n",
        "\n",
        "# token = tokenizer_BERT(sample_sequence, \n",
        "#                   max_length         = MAX_LEN, \n",
        "#                   truncation         = True, \n",
        "#                   padding            = 'max_length',\n",
        "#                   add_special_tokens = True,\n",
        "#                   return_tensors     = \"np\"\n",
        "#                  )\n",
        "    \n",
        "# print('\\ninput_ids:')\n",
        "# print(token['input_ids'])\n",
        "# print('\\nattention_mask:')\n",
        "# print(token['attention_mask'])\n",
        "# print(token['attention_mask'].sum())\n",
        "# print(len(tokenizer_BERT.tokenize(sample_sequence)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1hWIbG_C3-Q"
      },
      "outputs": [],
      "source": [
        "def bert_encode(texts, tokenizer = tokenizer_BERT):\n",
        "\n",
        "    token = tokenizer(texts, \n",
        "                      max_length         = MAX_LEN, \n",
        "                      truncation         = True, \n",
        "                      padding            = \"max_length\",\n",
        "                      add_special_tokens = True,\n",
        "                      return_tensors     = \"tf\")\n",
        "        \n",
        "    input_ids = token['input_ids']\n",
        "    attention_mask = token['attention_mask']\n",
        "    \n",
        "    return input_ids[0], attention_mask[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1OcgxMV290v"
      },
      "source": [
        "Let's have a look at what the tokenizer does with one sample:\n",
        "\n",
        "The function bert_encode() returns two arrays: input_ids andattention_mask\n",
        "\n",
        "https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
        "\n",
        "*   input_ids — List of token ids to be fed to a model.\n",
        "\n",
        "*    attention_mask — List of indices specifying which tokens should be attended to by the model (when return_attention_mask=True or if “attention_mask” is in self.model_input_names)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koxsfXmY-3cC"
      },
      "source": [
        "# Creation modele"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxmMSZ_d-8zL"
      },
      "source": [
        "## Hyper-paramètres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhWKw3GQ0fNs"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "BATCH_SIZE = 8\n",
        "DROPOUT = 0.1\n",
        "LEARNING_RATE = 1e-4\n",
        "MAX_LEN = MAX_LEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e9014V8478rw",
        "outputId": "a1973457-1ef3-42a5-e58c-2da74a93e93f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
            "\n",
            "All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a375c9dc2bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransformer_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_hidden_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mclf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"tf_deberta_v2_model_4\" (type TFDebertaV2Model).\n\nin user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\", line 1190, in run_call_with_unpacked_inputs  *\n        return func(self, **unpacked_inputs)\n    File \"/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py\", line 1193, in call  *\n        outputs = self.deberta(\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"deberta\" (type TFDebertaV2MainLayer).\n    \n    in user code:\n    \n        File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\", line 1190, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py\", line 1040, in call  *\n            embedding_output = self.embeddings(\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer \"embeddings\" (type TFDebertaV2Embeddings).\n        \n        in user code:\n        \n            File \"/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_tf_deberta_v2.py\", line 897, in call  *\n                final_embeddings = final_embeddings * mask\n        \n            ValueError: Dimensions must be equal, but are 768 and 270 for '{{node tf_deberta_v2_model_4/deberta/embeddings/mul}} = Mul[T=DT_FLOAT](tf_deberta_v2_model_4/deberta/embeddings/LayerNorm/batchnorm/add_1, Placeholder_1)' with input shapes: [?,270,768], [?,270,270].\n        \n        \n        Call arguments received:\n          • input_ids=tf.Tensor(shape=(None, 270), dtype=int32)\n          • position_ids=None\n          • token_type_ids=tf.Tensor(shape=(None, 270), dtype=int32)\n          • inputs_embeds=None\n          • mask=tf.Tensor(shape=(None, 270, 270), dtype=float32)\n          • training=False\n    \n    \n    Call arguments received:\n      • self=tf.Tensor(shape=(None, 270), dtype=int32)\n      • input_ids=None\n      • attention_mask=tf.Tensor(shape=(None, 270, 270), dtype=float32)\n      • token_type_ids=None\n      • position_ids=None\n      • inputs_embeds=None\n      • output_attentions=False\n      • output_hidden_states=False\n      • return_dict=True\n      • training=False\n\n\nCall arguments received:\n  • self=['tf.Tensor(shape=(None, 270), dtype=int32)', 'tf.Tensor(shape=(None, 270, 270), dtype=float32)']\n  • input_ids=None\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
          ]
        }
      ],
      "source": [
        "input_ids = tensorflow.keras.Input(shape = (MAX_LEN, ), dtype = tensorflow.int32, name = \"input_ids\")\n",
        "attention_mask = tensorflow.keras.Input(shape = (MAX_LEN, ), dtype = tensorflow.int32, name = \"attention_mask\")\n",
        "\n",
        "transformer_layer = (transformers.TFAutoModel.from_pretrained(MODEL_NAME))\n",
        "\n",
        "sequence_output = transformer_layer([input_ids, attention_mask])['last_hidden_state']\n",
        "clf_output = sequence_output[:, 0, :]\n",
        "layer = tensorflow.keras.layers.Dropout(0.4)(clf_output)\n",
        "layer = tensorflow.keras.layers.Dense(1152, activation=\"relu\")(layer)\n",
        "layer = tensorflow.keras.layers.Dropout(0.4)(layer)\n",
        "layer = tensorflow.keras.layers.Dense(128, activation=\"relu\")(layer)\n",
        "layer = tensorflow.keras.layers.Dropout(DROPOUT)(layer)\n",
        "out = tensorflow.keras.layers.Dense(3, activation='softmax')(layer)\n",
        "\n",
        "model = tensorflow.keras.Model(inputs = [input_ids, attention_mask], \n",
        "              outputs = out)\n",
        "\n",
        "model.compile(tensorflow.keras.optimizers.Adam(learning_rate = LEARNING_RATE), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JbSvTZ2A3c1"
      },
      "source": [
        "## Resumé du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaptcPcyTHZh"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F31pjBm4Z11u"
      },
      "outputs": [],
      "source": [
        "X = df_effective_args['discourse_type_SEP_discourse_text']\n",
        "y = df_effective_args['discourse_effectiveness_number']\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "y_train = list(y_train)\n",
        "y_valid= list(y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqCTu0Wvky1c"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.transform(bert_encode)\n",
        "X_valid = X_valid.transform(bert_encode)\n",
        "X_train_words_encoded, X_train_mask = zip(*X_train)\n",
        "X_valid_words_encoded, X_valid_mask = zip(*X_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_pcrFn3SZoQ"
      },
      "source": [
        "Dataset Valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyMSnGwgSYlt"
      },
      "outputs": [],
      "source": [
        "valid_input_words_dataset = (\n",
        "            tensorflow.data.Dataset\n",
        "            .from_tensor_slices((list(X_valid_words_encoded)))\n",
        "            .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "\n",
        "valid_input_mask_dataset = (\n",
        "            tensorflow.data.Dataset\n",
        "            .from_tensor_slices((list(X_valid_mask)))\n",
        "            .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "valid_output_dataset = (\n",
        "            tensorflow.data.Dataset\n",
        "            .from_tensor_slices((y_valid))\n",
        "            .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "data_valid_words_mask = tensorflow.data.Dataset.zip((valid_input_words_dataset, valid_input_mask_dataset))\n",
        "data_valid = tensorflow.data.Dataset.zip((data_valid_words_mask, valid_output_dataset))\n",
        "print(data_valid.element_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T1FnyWJSeJB"
      },
      "source": [
        "Dataset train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXpBt1MFSde-"
      },
      "outputs": [],
      "source": [
        "train_input_words_dataset = (\n",
        "            tensorflow.data.Dataset\n",
        "            .from_tensor_slices((list(X_train_words_encoded)))\n",
        "            .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "\n",
        "train_input_mask_dataset = (\n",
        "            tensorflow.data.Dataset\n",
        "            .from_tensor_slices((list(X_train_mask)))\n",
        "            .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "train_output_dataset = (\n",
        "            tensorflow.data.Dataset\n",
        "            .from_tensor_slices((y_train))\n",
        "            .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "data_train_words_mask = tensorflow.data.Dataset.zip((train_input_words_dataset, train_input_mask_dataset))\n",
        "data_train = tensorflow.data.Dataset.zip((data_train_words_mask, train_output_dataset))\n",
        "\n",
        "print(data_train.element_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "967gHtRQCbKR"
      },
      "source": [
        "## Entrainement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvnPo4g9MCJD"
      },
      "outputs": [],
      "source": [
        "Stopping_condition = tensorflow.keras.callbacks.EarlyStopping(\n",
        "    monitor='valid_loss',\n",
        "    min_delta=0.03,\n",
        "    patience=4,\n",
        "    #mode='max',\n",
        "    verbose=1)\n",
        "\n",
        "history = model.fit(\n",
        "    data_train, \n",
        "    epochs=50,\n",
        "    #validation_steps = validation_size // batch_size,\n",
        "    validation_data=data_valid,\n",
        "    #steps_per_epoch = train_size // batch_size,\n",
        "    callbacks=[Stopping_condition]    \n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/P8/models/bert.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAiMkcqsUtDe"
      },
      "outputs": [],
      "source": [
        "plot_curves(history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "P8_BERT_LARGE_MODEL.ipynb",
      "provenance": [],
      "mount_file_id": "1_rZ5-cvmMgaB3KDr-nJlVWRXsDRdY0yV",
      "authorship_tag": "ABX9TyMNJJRCCpc3S7Ehn0vPY61Q",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}