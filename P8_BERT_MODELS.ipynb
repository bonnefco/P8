{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonnefco/P8/blob/main/P8_BERT_MODELS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation des librairies"
      ],
      "metadata": {
        "id": "zfREIvCPHHSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import ast\n",
        "from scipy import stats\n",
        "import tensorflow\n",
        "from transformers import TFAutoModel\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "SWSzYlbMK8fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7021K76tiaBW",
        "outputId": "e2d0b837-11cc-4825-8787-aab13c1bd379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_curves(history):\n",
        "  #print(history.history.keys())\n",
        "  # print(history.history['accuracy'])\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'valid'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "EWFT7iW3iTfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_effective_args = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/P8/dataset/train_light.csv',encoding=\"utf-8\",header=(0))\n",
        "df_effective_args"
      ],
      "metadata": {
        "id": "SxU2y1tJRj-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f02e10fe-ea11-4001-acf9-ec0b166be56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          discourse_text  \\\n",
              "0      Hi, i'm Isaac, i'm going to be writing about h...   \n",
              "1      On my perspective, I think that the face is a ...   \n",
              "2      I think that the face is a natural landform be...   \n",
              "3      If life was on Mars, we would know by now. The...   \n",
              "4      People thought that the face was formed by ali...   \n",
              "...                                                  ...   \n",
              "36672  For many people they don't like only asking on...   \n",
              "36673  also people have different views and opinions ...   \n",
              "36674  Advice is something that can impact a persons ...   \n",
              "36675  someone can use everything that many people sa...   \n",
              "36676  In conclusion asking for an opinion can be ben...   \n",
              "\n",
              "             discourse_type discourse_effectiveness  \n",
              "0                      Lead                Adequate  \n",
              "1                  Position                Adequate  \n",
              "2                     Claim                Adequate  \n",
              "3                  Evidence                Adequate  \n",
              "4              Counterclaim                Adequate  \n",
              "...                     ...                     ...  \n",
              "36672                 Claim                Adequate  \n",
              "36673                 Claim                Adequate  \n",
              "36674              Position                Adequate  \n",
              "36675              Evidence             Ineffective  \n",
              "36676  Concluding Statement             Ineffective  \n",
              "\n",
              "[36677 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28eff0a5-79ea-4de9-a802-c5b6459d2f27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If life was on Mars, we would know by now. The...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>People thought that the face was formed by ali...</td>\n",
              "      <td>Counterclaim</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36672</th>\n",
              "      <td>For many people they don't like only asking on...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36673</th>\n",
              "      <td>also people have different views and opinions ...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36674</th>\n",
              "      <td>Advice is something that can impact a persons ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36675</th>\n",
              "      <td>someone can use everything that many people sa...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Ineffective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36676</th>\n",
              "      <td>In conclusion asking for an opinion can be ben...</td>\n",
              "      <td>Concluding Statement</td>\n",
              "      <td>Ineffective</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36677 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28eff0a5-79ea-4de9-a802-c5b6459d2f27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28eff0a5-79ea-4de9-a802-c5b6459d2f27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28eff0a5-79ea-4de9-a802-c5b6459d2f27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 879
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 256 \n",
        "DROPOUT = 0.1\n",
        "LEARNING_RATE = 1e-5\n",
        "EPOCHS = 1\n",
        "MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\""
      ],
      "metadata": {
        "id": "IhWKw3GQ0fNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "ezVhGxtq0f-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "credits : https://www.kaggle.com/code/iamleonie/feedback-prize-eda-starter-for-beginners\n",
        "\n",
        "Get the sep_token from the tokenizer and create the input sequences from discourse_type and discourse_text.\n",
        "\n",
        "sep_token - A special token separating two different sentences in the same input (see https://huggingface.co/docs/transformers/main_classes/tokenizer)"
      ],
      "metadata": {
        "id": "P9cjSazV2Wgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sep = tokenizer.sep_token\n",
        "print(sep)\n",
        "\n",
        "df_effective_args['discourse_type_SEP_discourse_text'] = df_effective_args.discourse_type + sep + df_effective_args.discourse_text\n",
        "df_effective_args.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "xMTL-JjH1C62",
        "outputId": "5a0e1f7a-7ee2-4884-b291-565ee3646f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SEP]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      discourse_text discourse_type  \\\n",
              "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
              "1  On my perspective, I think that the face is a ...       Position   \n",
              "2  I think that the face is a natural landform be...          Claim   \n",
              "\n",
              "  discourse_effectiveness                  discourse_type_SEP_discourse_text  \n",
              "0                Adequate  Lead[SEP]Hi, i'm Isaac, i'm going to be writin...  \n",
              "1                Adequate  Position[SEP]On my perspective, I think that t...  \n",
              "2                Adequate  Claim[SEP]I think that the face is a natural l...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9a1ac0c-c84e-4ee0-ab74-8aedb499cecb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>discourse_type_SEP_discourse_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Lead[SEP]Hi, i'm Isaac, i'm going to be writin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Position[SEP]On my perspective, I think that t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Claim[SEP]I think that the face is a natural l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9a1ac0c-c84e-4ee0-ab74-8aedb499cecb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9a1ac0c-c84e-4ee0-ab74-8aedb499cecb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9a1ac0c-c84e-4ee0-ab74-8aedb499cecb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 882
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at what the tokenizer does with one sample:\n",
        "\n",
        "The function bert_encode() returns two arrays: input_ids andattention_mask\n",
        "\n",
        "https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
        "\n",
        "*   input_ids — List of token ids to be fed to a model.\n",
        "\n",
        "*    attention_mask — List of indices specifying which tokens should be attended to by the model (when return_attention_mask=True or if “attention_mask” is in self.model_input_names)."
      ],
      "metadata": {
        "id": "N1OcgxMV290v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mdifier discourse effectuvness"
      ],
      "metadata": {
        "id": "IDzMO6v7nCuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_effective_args[\"number\"] = df_effective_args[\"discourse_effectiveness\"].replace({\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2})"
      ],
      "metadata": {
        "id": "RMv2kUA2nFC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Sample input sequence:')\n",
        "sample_sequence = df_effective_args['discourse_type_SEP_discourse_text'].iloc[0]\n",
        "print(sample_sequence)\n",
        "\n",
        "print('\\nTokenized sequence:')\n",
        "print(tokenizer.tokenize(sample_sequence))\n",
        "\n",
        "token = tokenizer(sample_sequence, \n",
        "                  max_length         = MAX_LEN, \n",
        "                  truncation         = True, \n",
        "                  padding            = 'max_length',\n",
        "                  add_special_tokens = True,\n",
        "                  return_tensors     = \"np\"\n",
        "                 )\n",
        "    \n",
        "print('\\ninput_ids:')\n",
        "print(len(token['input_ids']))\n",
        "print('\\nattention_mask:')\n",
        "print(token['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wafMjT0Y3uxe",
        "outputId": "b9b3b680-9376-48fb-a2f9-ce52f8832ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input sequence:\n",
            "Lead[SEP]Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. \n",
            "\n",
            "Tokenized sequence:\n",
            "['lead', '[SEP]', 'hi', ',', 'i', \"'\", 'm', 'isaac', ',', 'i', \"'\", 'm', 'going', 'to', 'be', 'writing', 'about', 'how', 'this', 'face', 'on', 'mars', 'is', 'a', 'natural', 'land', '##form', 'or', 'if', 'there', 'is', 'life', 'on', 'mars', 'that', 'made', 'it', '.', 'the', 'story', 'is', 'about', 'how', 'nasa', 'took', 'a', 'picture', 'of', 'mars', 'and', 'a', 'face', 'was', 'seen', 'on', 'the', 'planet', '.', 'nasa', 'doesn', \"'\", 't', 'know', 'if', 'the', 'land', '##form', 'was', 'created', 'by', 'life', 'on', 'mars', ',', 'or', 'if', 'it', 'is', 'just', 'a', 'natural', 'land', '##form', '.']\n",
            "\n",
            "input_ids:\n",
            "1\n",
            "\n",
            "attention_mask:\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_encode(texts, tokenizer = tokenizer, max_len = MAX_LEN):\n",
        "\n",
        "    token = tokenizer(texts, \n",
        "                      max_length         = max_len, \n",
        "                      truncation         = True, \n",
        "                      padding            = \"max_length\",\n",
        "                      add_special_tokens = True,\n",
        "                      return_tensors     = \"np\")\n",
        "        \n",
        "    input_ids = token['input_ids']\n",
        "    attention_mask = token['attention_mask']\n",
        "    return [input_ids[0], attention_mask[0]]"
      ],
      "metadata": {
        "id": "WXHB-9Mn4jIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_encode_v2(texts, tokenizer = tokenizer, max_len = MAX_LEN):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks)"
      ],
      "metadata": {
        "id": "y5G8WBD9RTZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bert_encode_v2(sample_sequence, tokenizer, max_len = MAX_LEN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKGbwkdRRfF5",
        "outputId": "3685f941-b03e-49a3-ea51-2e40121e0f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[ 101, 1048,  102, ...,    0,    0,    0],\n",
            "       [ 101, 1041,  102, ...,    0,    0,    0],\n",
            "       [ 101, 1037,  102, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 101, 1049,  102, ...,    0,    0,    0],\n",
            "       [ 101, 1012,  102, ...,    0,    0,    0],\n",
            "       [ 101,  102,    0, ...,    0,    0,    0]]), array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 0, ..., 0, 0, 0]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bert_encode(sample_sequence, tokenizer, max_len = MAX_LEN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuzY_baq7a9o",
        "outputId": "dfa03d8e-ae70-41c9-a66f-9e6cb0464f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([  101,  2599,   102,  7632,  1010,  1045,  1005,  1049,  7527,\n",
            "        1010,  1045,  1005,  1049,  2183,  2000,  2022,  3015,  2055,\n",
            "        2129,  2023,  2227,  2006,  7733,  2003,  1037,  3019,  2455,\n",
            "       14192,  2030,  2065,  2045,  2003,  2166,  2006,  7733,  2008,\n",
            "        2081,  2009,  1012,  1996,  2466,  2003,  2055,  2129,  9274,\n",
            "        2165,  1037,  3861,  1997,  7733,  1998,  1037,  2227,  2001,\n",
            "        2464,  2006,  1996,  4774,  1012,  9274,  2987,  1005,  1056,\n",
            "        2113,  2065,  1996,  2455, 14192,  2001,  2580,  2011,  2166,\n",
            "        2006,  7733,  1010,  2030,  2065,  2009,  2003,  2074,  1037,\n",
            "        3019,  2455, 14192,  1012,   102,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorflow.keras.backend.clear_session()\n",
        "\n",
        "input_ids = tensorflow.keras.Input(shape = (MAX_LEN, ), dtype = tensorflow.int32, name = \"input_ids\")\n",
        "attention_mask = tensorflow.keras.Input(shape = (MAX_LEN, ), dtype = tensorflow.int32, name = \"attention_mask\")\n",
        "\n",
        "transformer_layer = (transformers.TFAutoModel.from_pretrained(MODEL_NAME))\n",
        "\n",
        "sequence_output = transformer_layer([input_ids, attention_mask])['last_hidden_state']\n",
        "\n",
        "# print(transformer_layer(input_ids, attention_mask))\n",
        "# print(sequence_output)\n",
        "# print(type(transformer_layer(input_ids, attention_mask)))\n",
        "# print(type(sequence_output))\n",
        "\n",
        "# intermediate_layer = Dense(512, activation='relu', name='intermediate_layer')(sequence_output)\n",
        "\n",
        "clf_output = sequence_output[:, 0, :]\n",
        "clf_output = tensorflow.keras.layers.Dropout(DROPOUT)(clf_output)\n",
        "out = tensorflow.keras.layers.Dense(3, activation='softmax')(clf_output)\n",
        "\n",
        "model = tensorflow.keras.Model(inputs = [input_ids, attention_mask], \n",
        "              outputs = out)\n",
        "\n",
        "model.compile(tensorflow.keras.optimizers.Adam(learning_rate = LEARNING_RATE), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9014V8478rw",
        "outputId": "174e56dc-a516-4885-d61c-6e5ed545dc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertModel: ['dropout_19', 'pre_classifier', 'classifier']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BTKj34TLh2B",
        "outputId": "a6ed659a-5a2c-4481-886f-664f45ceff0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model (TFDistil  TFBaseModelOutput(l  66362880   ['input_ids[0][0]',              \n",
            " BertModel)                     ast_hidden_state=(N               'attention_mask[0][0]']         \n",
            "                                one, 256, 768),                                                   \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_distil_bert_model[0][0]']   \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 768)          0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            2307        ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,365,187\n",
            "Trainable params: 66,365,187\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_effective_args['discourse_type_SEP_discourse_text']\n",
        "y = df_effective_args['number']\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = X_train[100:120]\n",
        "X_valid = X_valid[:5]\n",
        "y_train = list(y_train[100:120])\n",
        "y_valid= list(y_valid[:5])"
      ],
      "metadata": {
        "id": "F31pjBm4Z11u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = list(X_train.transform(bert_encode))\n",
        "X_valid = list(X_valid.transform(bert_encode))"
      ],
      "metadata": {
        "id": "BqCTu0Wvky1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_words_encoded, X_train_mask = zip(*X_train)\n",
        "X_valid_words_encoded, X_valid_mask = zip(*X_valid)"
      ],
      "metadata": {
        "id": "gUl2po9qU5xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = (\n",
        "            tensorflow.data.Dataset\n",
        "            .from_tensor_slices((list(X_train_words_encoded), list(X_train_mask), y_train))\n",
        "            .batch(2)\n",
        ")\n",
        "\n",
        "\n",
        "valid_dataset = (\n",
        "            tensorflow.data.Dataset\n",
        "            .from_tensor_slices((list(X_valid_words_encoded), list(X_valid_mask), y_valid))\n",
        "            .batch(2)\n",
        "        )\n",
        "\n",
        "Stopping_condition = tensorflow.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0.05,\n",
        "    patience=15,\n",
        "    #mode='max',\n",
        "    verbose=1)\n",
        "\n",
        "print(valid_dataset)\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset, \n",
        "    epochs=1,\n",
        "    #validation_steps = validation_size // batch_size,\n",
        "    validation_data=valid_dataset,\n",
        "    #steps_per_epoch = train_size // batch_size,\n",
        "    callbacks=[Stopping_condition]    \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "QvnPo4g9MCJD",
        "outputId": "fded8fba-622b-40bf-a80c-08bd561fb270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-894-fca7c2732da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#steps_per_epoch = train_size // batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStopping_condition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 256) dtype=int64>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-WUUXwdfF2c9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "P8_BERT_MODELS.ipynb",
      "provenance": [],
      "mount_file_id": "1_rZ5-cvmMgaB3KDr-nJlVWRXsDRdY0yV",
      "authorship_tag": "ABX9TyMPSd6mH42FYlEPyp+ULR7f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}